{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Murcielago System V1 - Training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_dataset import GunShotsNoisesDataset, split_dataset\n",
    "import numpy as np\n",
    "from cnn import ShotDetectionNetwork\n",
    "from torch import nn\n",
    "from train_test_functions import train_step, test_step, eval_model, accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data preparing: Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"./dataset/metadata.xlsx\"\n",
    "audios_dir = \"./dataset\"\n",
    "fs = 48000\n",
    "scales = np.arange(1, 129)\n",
    "transformation_dict = {\"wavelet\": \"cmor\",\"scales\":scales}\n",
    "\n",
    "GSN_visualize = GunShotsNoisesDataset(metadata_file, audios_dir, transformation_dict, fs, 0.01) #this returns audio waveform to analyse samples\n",
    "\n",
    "GSN_dataset = GunShotsNoisesDataset(metadata_file, audios_dir, transformation_dict, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_data, test_data = split_dataset(GSN_dataset, 0.04)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShotDetectionNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d(64, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): LazyLinear(in_features=0, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "mur_cnn_v1 = ShotDetectionNetwork(64)\n",
    "print(mur_cnn_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.02\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(mur_cnn_v1.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaqo\\anaconda3\\envs\\Sonido\\Lib\\site-packages\\pywt\\_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 43.98751 | Train accuracy: 93.54167%\n",
      "Test loss: 391.80859 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 1\n",
      "Train loss: 40.80391 | Train accuracy: 92.91667%\n",
      "Test loss: 36.17511 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 11.00864 | Train accuracy: 95.83333%\n",
      "Test loss: 4927.61035 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 374.76306 | Train accuracy: 88.95833%\n",
      "Test loss: 6000.67383 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 650.47595 | Train accuracy: 91.04167%\n",
      "Test loss: 8708.41699 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 477.19217 | Train accuracy: 85.83333%\n",
      "Test loss: 3549.85229 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 6\n",
      "Train loss: 276.53214 | Train accuracy: 83.75000%\n",
      "Test loss: 254.69119 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 7\n",
      "Train loss: 231.78171 | Train accuracy: 82.50000%\n",
      "Test loss: 858.88477 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 8\n",
      "Train loss: 121.97459 | Train accuracy: 89.79167%\n",
      "Test loss: 814.98193 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 9\n",
      "Train loss: 71.20979 | Train accuracy: 83.54167%\n",
      "Test loss: 73.42629 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 10\n",
      "Train loss: 13.58930 | Train accuracy: 73.33333%\n",
      "Test loss: 6.97052 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 11\n",
      "Train loss: 2.61341 | Train accuracy: 64.16667%\n",
      "Test loss: 1.90466 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 12\n",
      "Train loss: 0.94138 | Train accuracy: 70.20833%\n",
      "Test loss: 1.08699 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 13\n",
      "Train loss: 0.52751 | Train accuracy: 82.08333%\n",
      "Test loss: 1.43607 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 14\n",
      "Train loss: 0.55914 | Train accuracy: 82.08333%\n",
      "Test loss: 1.09188 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 15\n",
      "Train loss: 0.45545 | Train accuracy: 83.75000%\n",
      "Test loss: 1.94272 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 16\n",
      "Train loss: 0.56558 | Train accuracy: 82.50000%\n",
      "Test loss: 1.88935 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 17\n",
      "Train loss: 0.53357 | Train accuracy: 81.87500%\n",
      "Test loss: 1.90289 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 18\n",
      "Train loss: 0.52312 | Train accuracy: 81.66667%\n",
      "Test loss: 1.76213 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 19\n",
      "Train loss: 0.49234 | Train accuracy: 81.87500%\n",
      "Test loss: 1.74652 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 20\n",
      "Train loss: 0.47798 | Train accuracy: 82.08333%\n",
      "Test loss: 1.57088 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 21\n",
      "Train loss: 0.44792 | Train accuracy: 83.95833%\n",
      "Test loss: 1.56403 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 22\n",
      "Train loss: 0.43376 | Train accuracy: 84.58333%\n",
      "Test loss: 1.58729 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 23\n",
      "Train loss: 0.42807 | Train accuracy: 84.79167%\n",
      "Test loss: 1.67366 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 24\n",
      "Train loss: 0.42912 | Train accuracy: 86.04167%\n",
      "Test loss: 1.61312 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 25\n",
      "Train loss: 0.40056 | Train accuracy: 86.45833%\n",
      "Test loss: 1.67579 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 26\n",
      "Train loss: 0.39405 | Train accuracy: 86.45833%\n",
      "Test loss: 1.77266 | Test accuracy: 45.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 27\n",
      "Train loss: 0.44240 | Train accuracy: 85.20833%\n",
      "Test loss: 1.87122 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 28\n",
      "Train loss: 0.51767 | Train accuracy: 86.25000%\n",
      "Test loss: 2.41423 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 29\n",
      "Train loss: 0.66894 | Train accuracy: 85.20833%\n",
      "Test loss: 2.55478 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 30\n",
      "Train loss: 0.77877 | Train accuracy: 84.58333%\n",
      "Test loss: 2.48038 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 31\n",
      "Train loss: 0.80542 | Train accuracy: 82.91667%\n",
      "Test loss: 2.20249 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 32\n",
      "Train loss: 0.86776 | Train accuracy: 86.66667%\n",
      "Test loss: 3.79636 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 33\n",
      "Train loss: 0.89649 | Train accuracy: 84.16667%\n",
      "Test loss: 3.12211 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 34\n",
      "Train loss: 0.75220 | Train accuracy: 82.50000%\n",
      "Test loss: 0.90274 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 35\n",
      "Train loss: 0.30615 | Train accuracy: 90.00000%\n",
      "Test loss: 2.02508 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 36\n",
      "Train loss: 0.50275 | Train accuracy: 83.75000%\n",
      "Test loss: 1.28469 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 37\n",
      "Train loss: 0.36077 | Train accuracy: 89.37500%\n",
      "Test loss: 2.51728 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 38\n",
      "Train loss: 0.59587 | Train accuracy: 82.29167%\n",
      "Test loss: 0.80036 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 39\n",
      "Train loss: 0.29280 | Train accuracy: 90.20833%\n",
      "Test loss: 1.98870 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 40\n",
      "Train loss: 0.44322 | Train accuracy: 87.08333%\n",
      "Test loss: 1.70913 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 41\n",
      "Train loss: 0.44088 | Train accuracy: 86.87500%\n",
      "Test loss: 1.08308 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 42\n",
      "Train loss: 0.33422 | Train accuracy: 88.33333%\n",
      "Test loss: 1.79273 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 43\n",
      "Train loss: 0.41561 | Train accuracy: 85.83333%\n",
      "Test loss: 1.25037 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 44\n",
      "Train loss: 0.34327 | Train accuracy: 90.00000%\n",
      "Test loss: 1.86520 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 45\n",
      "Train loss: 0.44589 | Train accuracy: 85.00000%\n",
      "Test loss: 1.08768 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 46\n",
      "Train loss: 0.30411 | Train accuracy: 90.00000%\n",
      "Test loss: 1.97683 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 47\n",
      "Train loss: 0.45781 | Train accuracy: 85.62500%\n",
      "Test loss: 0.87826 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 48\n",
      "Train loss: 0.33884 | Train accuracy: 86.87500%\n",
      "Test loss: 1.78646 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 49\n",
      "Train loss: 0.44691 | Train accuracy: 85.41667%\n",
      "Test loss: 4.30619 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 50\n",
      "Train loss: 0.77265 | Train accuracy: 87.50000%\n",
      "Test loss: 6.46042 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 51\n",
      "Train loss: 0.97772 | Train accuracy: 82.91667%\n",
      "Test loss: 0.83528 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 52\n",
      "Train loss: 0.38062 | Train accuracy: 86.04167%\n",
      "Test loss: 1.98132 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 53\n",
      "Train loss: 0.42991 | Train accuracy: 86.87500%\n",
      "Test loss: 0.37367 | Test accuracy: 80.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 54\n",
      "Train loss: 0.30463 | Train accuracy: 86.66667%\n",
      "Test loss: 0.29524 | Test accuracy: 80.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 55\n",
      "Train loss: 0.29699 | Train accuracy: 88.54167%\n",
      "Test loss: 2.16121 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 56\n",
      "Train loss: 0.45001 | Train accuracy: 87.91667%\n",
      "Test loss: 2.80066 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 57\n",
      "Train loss: 0.38396 | Train accuracy: 87.70833%\n",
      "Test loss: 1.05207 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 58\n",
      "Train loss: 0.65728 | Train accuracy: 83.54167%\n",
      "Test loss: 3.62517 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 59\n",
      "Train loss: 0.91844 | Train accuracy: 87.50000%\n",
      "Test loss: 4.53883 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 60\n",
      "Train loss: 0.67812 | Train accuracy: 90.00000%\n",
      "Test loss: 6.69906 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 61\n",
      "Train loss: 0.76935 | Train accuracy: 92.70833%\n",
      "Test loss: 112.26048 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 62\n",
      "Train loss: 9.23665 | Train accuracy: 93.95833%\n",
      "Test loss: 3500.28906 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 63\n",
      "Train loss: 4585.12354 | Train accuracy: 95.83333%\n",
      "Test loss: 180899.40625 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 64\n",
      "Train loss: 14126.88574 | Train accuracy: 91.45833%\n",
      "Test loss: 181982.62500 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 65\n",
      "Train loss: 11224.57520 | Train accuracy: 73.75000%\n",
      "Test loss: 9491.68164 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 66\n",
      "Train loss: 1564.62561 | Train accuracy: 83.54167%\n",
      "Test loss: 2906.69043 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 67\n",
      "Train loss: 694.42743 | Train accuracy: 72.50000%\n",
      "Test loss: 720.43823 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 68\n",
      "Train loss: 158.19830 | Train accuracy: 74.37500%\n",
      "Test loss: 234.66922 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 69\n",
      "Train loss: 59.63551 | Train accuracy: 69.16667%\n",
      "Test loss: 75.89360 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 70\n",
      "Train loss: 25.68792 | Train accuracy: 72.91667%\n",
      "Test loss: 57.58151 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 71\n",
      "Train loss: 18.52328 | Train accuracy: 74.37500%\n",
      "Test loss: 44.21713 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 72\n",
      "Train loss: 13.59765 | Train accuracy: 77.08333%\n",
      "Test loss: 24.01025 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 73\n",
      "Train loss: 8.54606 | Train accuracy: 78.33333%\n",
      "Test loss: 20.36952 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 74\n",
      "Train loss: 6.67318 | Train accuracy: 78.54167%\n",
      "Test loss: 14.58904 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 75\n",
      "Train loss: 5.07402 | Train accuracy: 80.62500%\n",
      "Test loss: 9.39259 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 76\n",
      "Train loss: 3.71780 | Train accuracy: 82.91667%\n",
      "Test loss: 7.46243 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 77\n",
      "Train loss: 3.00129 | Train accuracy: 83.95833%\n",
      "Test loss: 4.56666 | Test accuracy: 60.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 78\n",
      "Train loss: 2.16253 | Train accuracy: 86.04167%\n",
      "Test loss: 2.83111 | Test accuracy: 70.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 79\n",
      "Train loss: 1.77827 | Train accuracy: 86.45833%\n",
      "Test loss: 2.25483 | Test accuracy: 70.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 80\n",
      "Train loss: 1.47176 | Train accuracy: 87.50000%\n",
      "Test loss: 1.91838 | Test accuracy: 70.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 81\n",
      "Train loss: 1.28294 | Train accuracy: 87.70833%\n",
      "Test loss: 1.93350 | Test accuracy: 65.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 82\n",
      "Train loss: 1.19759 | Train accuracy: 87.29167%\n",
      "Test loss: 1.83242 | Test accuracy: 65.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 83\n",
      "Train loss: 1.08642 | Train accuracy: 87.50000%\n",
      "Test loss: 2.10661 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 84\n",
      "Train loss: 0.99821 | Train accuracy: 87.29167%\n",
      "Test loss: 1.39397 | Test accuracy: 60.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 85\n",
      "Train loss: 0.85318 | Train accuracy: 88.12500%\n",
      "Test loss: 2.44847 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 86\n",
      "Train loss: 0.87120 | Train accuracy: 87.50000%\n",
      "Test loss: 1.02521 | Test accuracy: 70.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 87\n",
      "Train loss: 0.66439 | Train accuracy: 89.37500%\n",
      "Test loss: 2.78418 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 88\n",
      "Train loss: 0.79384 | Train accuracy: 87.91667%\n",
      "Test loss: 2.33642 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 89\n",
      "Train loss: 0.75564 | Train accuracy: 87.91667%\n",
      "Test loss: 2.60721 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 90\n",
      "Train loss: 0.69507 | Train accuracy: 88.12500%\n",
      "Test loss: 2.58359 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 91\n",
      "Train loss: 0.79058 | Train accuracy: 87.91667%\n",
      "Test loss: 3.15545 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 92\n",
      "Train loss: 0.76027 | Train accuracy: 88.75000%\n",
      "Test loss: 4.79629 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 93\n",
      "Train loss: 0.98420 | Train accuracy: 86.66667%\n",
      "Test loss: 4.96741 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 94\n",
      "Train loss: 1.13993 | Train accuracy: 85.41667%\n",
      "Test loss: 2.61456 | Test accuracy: 55.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 95\n",
      "Train loss: 0.78249 | Train accuracy: 88.54167%\n",
      "Test loss: 3.08872 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 96\n",
      "Train loss: 0.75064 | Train accuracy: 89.79167%\n",
      "Test loss: 6.34135 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 97\n",
      "Train loss: 1.11695 | Train accuracy: 84.79167%\n",
      "Test loss: 2.95739 | Test accuracy: 50.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 98\n",
      "Train loss: 0.83912 | Train accuracy: 87.91667%\n",
      "Test loss: 1.79193 | Test accuracy: 60.00000%\n",
      "-----------------------------------------------------------\n",
      "Epoch: 99\n",
      "Train loss: 0.60225 | Train accuracy: 91.25000%\n",
      "Test loss: 3.47477 | Test accuracy: 50.00000%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train_step(mur_cnn_v1, train_dataloader, loss_fn, optim, accuracy_fn=accuracy_fn)\n",
    "    test_step(mur_cnn_v1, test_dataloader, loss_fn, accuracy_fn=accuracy_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-9.9889e-05, -1.5561e-04, -1.5939e-04, -1.6885e-04],\n",
      "          [-2.4373e-04, -2.7829e-04, -2.7474e-04, -2.6236e-04],\n",
      "          [-2.3959e-04, -2.5580e-04, -2.4904e-04, -2.5041e-04],\n",
      "          [-3.9101e-04, -3.9032e-04, -3.7250e-04, -3.4199e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4977e-04,  1.8734e-04,  1.7478e-04,  1.5097e-04],\n",
      "          [ 1.4052e-04,  1.8685e-04,  1.5654e-04,  1.2611e-04],\n",
      "          [ 2.4559e-04,  2.7943e-04,  2.6440e-04,  2.1128e-04],\n",
      "          [ 2.2559e-04,  2.7059e-04,  2.3894e-04,  1.8271e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.9087e-05, -1.4223e-04, -1.4970e-04, -1.6148e-04],\n",
      "          [-2.4970e-04, -2.8834e-04, -2.8630e-04, -2.7522e-04],\n",
      "          [-2.3419e-04, -2.5148e-04, -2.4533e-04, -2.5061e-04],\n",
      "          [-4.1436e-04, -4.1162e-04, -3.9314e-04, -3.6290e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3957e-04, -1.7910e-04, -1.7112e-04, -1.5208e-04],\n",
      "          [-1.9183e-04, -2.3021e-04, -2.0425e-04, -1.7540e-04],\n",
      "          [-2.7002e-04, -2.9064e-04, -2.7305e-04, -2.2849e-04],\n",
      "          [-3.1695e-04, -3.4064e-04, -3.0705e-04, -2.5396e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.2005e-04, -1.4545e-04, -1.3327e-04, -1.1142e-04],\n",
      "          [-9.1429e-05, -1.2867e-04, -1.0132e-04, -7.5061e-05],\n",
      "          [-1.9856e-04, -2.2607e-04, -2.1301e-04, -1.6469e-04],\n",
      "          [-1.6076e-04, -2.0330e-04, -1.7687e-04, -1.2992e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6067e-04,  1.9449e-04,  1.7746e-04,  1.5240e-04],\n",
      "          [ 1.6169e-04,  2.0161e-04,  1.7075e-04,  1.4040e-04],\n",
      "          [ 2.7096e-04,  2.9929e-04,  2.7925e-04,  2.2677e-04],\n",
      "          [ 2.5028e-04,  2.8778e-04,  2.5511e-04,  2.0069e-04]]]])\n",
      "tensor([-4.8969e-03, -4.0888e-04, -5.1288e-03, -2.7222e-04,  4.6146e-05,\n",
      "         3.0481e-03,  4.8798e-03,  2.0022e-03,  1.8235e-03,  2.4801e-04,\n",
      "         3.1351e-03,  5.4757e-03,  1.2780e-03,  3.9642e-03, -2.5610e-03,\n",
      "         3.1956e-03,  8.8814e-04, -3.9192e-03,  4.4058e-03, -1.8779e-03,\n",
      "        -5.6316e-03, -5.8916e-05, -2.4614e-03,  6.0072e-03,  3.1731e-03,\n",
      "         2.6722e-03, -1.1097e-03, -2.9451e-03,  1.5796e-03, -1.8466e-03,\n",
      "         1.3163e-03, -1.1796e-03,  1.8057e-03, -4.5842e-03, -5.5183e-03,\n",
      "         2.8607e-03,  7.0038e-03,  5.8670e-03,  2.7262e-03,  3.1449e-03,\n",
      "        -2.4101e-03,  2.6747e-03, -1.1779e-03, -2.4655e-03,  9.0608e-04,\n",
      "        -1.9843e-04, -1.1612e-03,  5.3714e-03,  3.1185e-03,  6.7638e-04,\n",
      "        -2.0727e-03, -1.8658e-03,  4.2644e-03, -4.6666e-03,  6.0117e-03,\n",
      "         8.8326e-04, -2.8407e-03, -3.6521e-03, -1.3617e-03, -5.8777e-03,\n",
      "        -4.3420e-03, -7.1904e-04,  1.1868e-03, -4.8503e-05])\n",
      "tensor([[[[-7.4709e-06,  1.7113e-05,  1.8698e-05,  1.9318e-05],\n",
      "          [-1.4512e-05,  9.1329e-06,  1.1018e-05,  1.1886e-05],\n",
      "          [-1.2727e-05,  1.0296e-05,  1.1617e-05,  1.1997e-05],\n",
      "          [-1.1855e-05,  1.0970e-05,  1.1790e-05,  1.1691e-05]],\n",
      "\n",
      "         [[ 9.0169e-06, -6.4155e-06, -9.1850e-06, -1.0491e-05],\n",
      "          [ 9.3810e-06, -3.7023e-06, -7.5278e-06, -1.0662e-05],\n",
      "          [ 4.9252e-06, -6.3959e-06, -7.1855e-06, -8.1627e-06],\n",
      "          [ 2.3403e-06, -9.0177e-06, -9.1862e-06, -9.5951e-06]],\n",
      "\n",
      "         [[-7.5422e-06,  2.4823e-05,  2.5529e-05,  2.5680e-05],\n",
      "          [-1.8593e-05,  1.3621e-05,  1.4525e-05,  1.4400e-05],\n",
      "          [-1.8112e-05,  1.3598e-05,  1.4192e-05,  1.4439e-05],\n",
      "          [-1.7873e-05,  1.4028e-05,  1.4579e-05,  1.4260e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0773e-06,  1.5037e-05,  1.4208e-05,  1.4560e-05],\n",
      "          [-1.0937e-05,  8.2527e-06,  7.6785e-06,  7.6273e-06],\n",
      "          [-1.1205e-05,  7.6607e-06,  8.5181e-06,  9.2518e-06],\n",
      "          [-9.7521e-06,  7.9946e-06,  7.6611e-06,  7.3610e-06]],\n",
      "\n",
      "         [[-8.1805e-06,  8.0519e-06,  1.0817e-05,  1.1814e-05],\n",
      "          [-9.8885e-06,  4.3921e-06,  7.7904e-06,  1.0109e-05],\n",
      "          [-6.5655e-06,  6.3577e-06,  8.0046e-06,  8.8819e-06],\n",
      "          [-4.2325e-06,  8.7426e-06,  9.0824e-06,  8.9674e-06]],\n",
      "\n",
      "         [[ 8.5679e-06, -4.2200e-06, -8.3099e-06, -9.5605e-06],\n",
      "          [ 8.7351e-06, -1.7008e-06, -5.9425e-06, -8.1221e-06],\n",
      "          [ 4.2643e-06, -4.8908e-06, -7.1787e-06, -8.2083e-06],\n",
      "          [ 2.0587e-06, -8.0511e-06, -9.0984e-06, -8.5871e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2369e-05, -1.8173e-05, -2.0957e-05, -2.1434e-05],\n",
      "          [-2.2690e-05, -3.6421e-05, -3.7901e-05, -3.8349e-05],\n",
      "          [-2.8148e-05, -3.5139e-05, -3.3705e-05, -3.6981e-05],\n",
      "          [-3.4304e-05, -3.7939e-05, -3.4498e-05, -3.7520e-05]],\n",
      "\n",
      "         [[-1.8991e-05,  1.0333e-05,  1.4651e-05,  1.5371e-05],\n",
      "          [ 6.0889e-06,  1.1478e-05,  1.5077e-05,  1.6946e-05],\n",
      "          [ 2.2195e-05,  9.2008e-06,  9.9067e-06,  1.5534e-05],\n",
      "          [ 4.0591e-05,  1.8170e-05,  1.2657e-05,  1.9550e-05]],\n",
      "\n",
      "         [[ 5.8530e-05, -2.6094e-05, -2.6840e-05, -2.7166e-05],\n",
      "          [-3.4346e-05, -5.2317e-05, -5.3112e-05, -5.3328e-05],\n",
      "          [-3.5129e-05, -5.1528e-05, -5.2467e-05, -5.3199e-05],\n",
      "          [-3.7820e-05, -5.2912e-05, -5.2158e-05, -5.3075e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2462e-05, -1.5683e-05, -1.5355e-05, -1.5126e-05],\n",
      "          [-1.9280e-05, -3.2693e-05, -3.1514e-05, -3.0394e-05],\n",
      "          [-1.8612e-05, -2.9470e-05, -3.2125e-05, -3.1866e-05],\n",
      "          [-1.9475e-05, -2.5722e-05, -2.8395e-05, -3.0353e-05]],\n",
      "\n",
      "         [[ 2.2929e-05, -1.0892e-05, -1.5181e-05, -1.5875e-05],\n",
      "          [-8.8945e-06, -1.6663e-05, -1.8881e-05, -2.0625e-05],\n",
      "          [-2.0600e-05, -1.4205e-05, -1.4819e-05, -1.9111e-05],\n",
      "          [-3.6081e-05, -2.1084e-05, -1.5706e-05, -2.1522e-05]],\n",
      "\n",
      "         [[-1.7144e-05,  6.8738e-06,  1.3279e-05,  1.4140e-05],\n",
      "          [ 5.8785e-06,  1.3178e-05,  1.4891e-05,  1.5451e-05],\n",
      "          [ 2.0973e-05,  1.0942e-05,  8.8461e-06,  1.3865e-05],\n",
      "          [ 3.7954e-05,  1.8751e-05,  8.9316e-06,  1.5095e-05]]],\n",
      "\n",
      "\n",
      "        [[[-8.4961e-05, -2.5837e-05, -2.2822e-05, -2.1897e-05],\n",
      "          [ 2.5826e-05,  3.0002e-05,  3.1467e-05,  3.2520e-05],\n",
      "          [ 3.6216e-05,  3.1758e-05,  2.9488e-05,  3.2596e-05],\n",
      "          [ 4.8757e-05,  3.8400e-05,  3.3199e-05,  3.7092e-05]],\n",
      "\n",
      "         [[ 4.2495e-05,  1.3414e-05,  8.8043e-06,  7.1200e-06],\n",
      "          [-2.9746e-06, -2.1763e-06, -6.8295e-06, -1.1181e-05],\n",
      "          [-3.4954e-05, -9.9613e-06, -9.3152e-06, -1.5948e-05],\n",
      "          [-6.9975e-05, -3.2079e-05, -2.1893e-05, -3.1466e-05]],\n",
      "\n",
      "         [[-1.1481e-04, -3.2854e-05, -3.2060e-05, -3.1427e-05],\n",
      "          [ 4.1248e-05,  4.6205e-05,  4.7399e-05,  4.7237e-05],\n",
      "          [ 4.2860e-05,  4.6339e-05,  4.6863e-05,  4.7619e-05],\n",
      "          [ 4.7758e-05,  4.9165e-05,  4.7974e-05,  4.8910e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3984e-05, -1.7366e-05, -1.7666e-05, -1.7567e-05],\n",
      "          [ 2.2707e-05,  2.9752e-05,  2.9028e-05,  2.7406e-05],\n",
      "          [ 2.1440e-05,  2.5038e-05,  3.0029e-05,  2.8976e-05],\n",
      "          [ 2.3133e-05,  2.1374e-05,  2.5375e-05,  2.6990e-05]],\n",
      "\n",
      "         [[-4.9405e-05, -1.6307e-05, -1.1589e-05, -9.9032e-06],\n",
      "          [ 6.8123e-06,  8.5006e-06,  1.1316e-05,  1.4665e-05],\n",
      "          [ 3.0476e-05,  1.3494e-05,  1.2781e-05,  1.7987e-05],\n",
      "          [ 5.9736e-05,  3.1049e-05,  2.1581e-05,  2.9077e-05]],\n",
      "\n",
      "         [[ 3.8789e-05,  1.4855e-05,  8.0358e-06,  6.1317e-06],\n",
      "          [-3.5262e-06, -6.0739e-06, -7.9316e-06, -1.1378e-05],\n",
      "          [-3.4030e-05, -1.3956e-05, -8.4691e-06, -1.4881e-05],\n",
      "          [-6.6272e-05, -3.2434e-05, -1.6909e-05, -2.4598e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.8938e-05,  2.1944e-05,  2.4120e-05,  2.4377e-05],\n",
      "          [ 2.3126e-05,  4.7942e-05,  4.9551e-05,  5.0048e-05],\n",
      "          [ 2.8246e-05,  4.8622e-05,  4.8154e-05,  4.9433e-05],\n",
      "          [ 3.3935e-05,  5.1474e-05,  4.9555e-05,  5.1237e-05]],\n",
      "\n",
      "         [[ 1.2464e-05, -1.3136e-05, -1.7000e-05, -1.7461e-05],\n",
      "          [-8.3378e-06, -1.9547e-05, -2.2907e-05, -2.4593e-05],\n",
      "          [-2.2627e-05, -2.1990e-05, -2.2560e-05, -2.5144e-05],\n",
      "          [-3.9400e-05, -3.1510e-05, -2.7757e-05, -3.1483e-05]],\n",
      "\n",
      "         [[-4.0690e-05,  2.9730e-05,  3.0497e-05,  3.0686e-05],\n",
      "          [ 3.3926e-05,  6.7856e-05,  6.8695e-05,  6.8795e-05],\n",
      "          [ 3.4837e-05,  6.7798e-05,  6.8413e-05,  6.8751e-05],\n",
      "          [ 3.7009e-05,  6.9036e-05,  6.8976e-05,  6.9256e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2495e-05,  1.7835e-05,  1.7189e-05,  1.7100e-05],\n",
      "          [ 1.8683e-05,  4.0230e-05,  3.9438e-05,  3.8923e-05],\n",
      "          [ 1.8101e-05,  3.8260e-05,  3.9923e-05,  3.9696e-05],\n",
      "          [ 1.8870e-05,  3.6146e-05,  3.7631e-05,  3.8090e-05]],\n",
      "\n",
      "         [[-1.5199e-05,  1.3830e-05,  1.7588e-05,  1.8025e-05],\n",
      "          [ 1.0623e-05,  2.4504e-05,  2.7175e-05,  2.8667e-05],\n",
      "          [ 2.1336e-05,  2.6073e-05,  2.6684e-05,  2.8752e-05],\n",
      "          [ 3.5184e-05,  3.3478e-05,  3.0182e-05,  3.3090e-05]],\n",
      "\n",
      "         [[ 1.0865e-05, -1.0177e-05, -1.5600e-05, -1.6035e-05],\n",
      "          [-7.6283e-06, -1.8333e-05, -2.1492e-05, -2.2680e-05],\n",
      "          [-2.1868e-05, -2.1546e-05, -2.0568e-05, -2.2837e-05],\n",
      "          [-3.7288e-05, -2.9416e-05, -2.3430e-05, -2.6510e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9441e-06, -6.2946e-07, -2.2034e-06, -2.4404e-06],\n",
      "          [-7.8661e-05, -4.7853e-05, -4.7961e-05, -4.7863e-05],\n",
      "          [-8.4749e-05, -4.7783e-05, -4.4344e-05, -4.6067e-05],\n",
      "          [-9.0176e-05, -4.8975e-05, -4.3630e-05, -4.6823e-05]],\n",
      "\n",
      "         [[-9.2547e-07,  6.6018e-06,  9.0295e-06,  8.8241e-06],\n",
      "          [ 3.2650e-05,  1.8178e-05,  1.9988e-05,  2.0132e-05],\n",
      "          [ 4.8867e-05,  1.8291e-05,  1.3971e-05,  1.7031e-05],\n",
      "          [ 6.4638e-05,  2.2791e-05,  1.2078e-05,  2.0931e-05]],\n",
      "\n",
      "         [[ 1.5050e-05,  1.1419e-06,  8.1061e-07,  7.0408e-07],\n",
      "          [-1.1251e-04, -6.7275e-05, -6.7411e-05, -6.7340e-05],\n",
      "          [-1.1347e-04, -6.6734e-05, -6.6724e-05, -6.7743e-05],\n",
      "          [-1.1558e-04, -6.7873e-05, -6.6866e-05, -6.7485e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1490e-06, -3.3763e-08, -6.9248e-08,  5.1761e-07],\n",
      "          [-6.1972e-05, -3.9456e-05, -3.9245e-05, -3.7938e-05],\n",
      "          [-6.2232e-05, -3.6802e-05, -4.0017e-05, -3.9120e-05],\n",
      "          [-6.3269e-05, -3.3561e-05, -3.6401e-05, -3.8168e-05]],\n",
      "\n",
      "         [[ 2.6994e-06, -4.7801e-06, -7.1740e-06, -6.8904e-06],\n",
      "          [-4.0274e-05, -2.4085e-05, -2.4498e-05, -2.5083e-05],\n",
      "          [-5.2284e-05, -2.3802e-05, -2.0191e-05, -2.2537e-05],\n",
      "          [-6.5737e-05, -2.7684e-05, -1.7735e-05, -2.4466e-05]],\n",
      "\n",
      "         [[-7.1045e-07,  5.4647e-06,  8.8863e-06,  9.0084e-06],\n",
      "          [ 2.8685e-05,  1.9649e-05,  1.8557e-05,  1.8975e-05],\n",
      "          [ 4.4402e-05,  2.0407e-05,  1.2343e-05,  1.5352e-05],\n",
      "          [ 5.8977e-05,  2.4140e-05,  8.5132e-06,  1.5123e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7161e-05, -1.5505e-05, -1.7875e-05, -1.8417e-05],\n",
      "          [ 8.5709e-06, -3.3969e-05, -3.6312e-05, -3.6959e-05],\n",
      "          [ 5.8747e-06, -3.5916e-05, -3.7748e-05, -3.7370e-05],\n",
      "          [ 2.9311e-06, -3.7414e-05, -3.8770e-05, -3.8718e-05]],\n",
      "\n",
      "         [[-1.4330e-05,  1.0894e-05,  1.5334e-05,  1.6588e-05],\n",
      "          [-5.0266e-06,  1.8269e-05,  2.2752e-05,  2.4446e-05],\n",
      "          [ 2.2671e-06,  2.3207e-05,  2.5958e-05,  2.6033e-05],\n",
      "          [ 1.0533e-05,  2.8696e-05,  2.9943e-05,  3.0363e-05]],\n",
      "\n",
      "         [[ 3.6795e-05, -2.0311e-05, -2.1455e-05, -2.1533e-05],\n",
      "          [ 1.0946e-05, -4.6959e-05, -4.7944e-05, -4.7972e-05],\n",
      "          [ 1.0382e-05, -4.7424e-05, -4.8110e-05, -4.8182e-05],\n",
      "          [ 9.5367e-06, -4.7966e-05, -4.8865e-05, -4.8636e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0636e-05, -1.3214e-05, -1.2070e-05, -1.2255e-05],\n",
      "          [ 6.5129e-06, -2.7363e-05, -2.7025e-05, -2.7176e-05],\n",
      "          [ 6.5903e-06, -2.7237e-05, -2.7083e-05, -2.7096e-05],\n",
      "          [ 6.0216e-06, -2.7242e-05, -2.6801e-05, -2.6174e-05]],\n",
      "\n",
      "         [[ 1.6381e-05, -1.0448e-05, -1.4893e-05, -1.5953e-05],\n",
      "          [ 5.7833e-06, -1.9798e-05, -2.4235e-05, -2.5667e-05],\n",
      "          [ 4.7075e-08, -2.3775e-05, -2.6653e-05, -2.6838e-05],\n",
      "          [-6.5668e-06, -2.8266e-05, -3.0002e-05, -3.0012e-05]],\n",
      "\n",
      "         [[-1.2656e-05,  7.9555e-06,  1.4044e-05,  1.5212e-05],\n",
      "          [-4.6573e-06,  1.4527e-05,  2.0858e-05,  2.2620e-05],\n",
      "          [ 3.2222e-06,  2.0126e-05,  2.4075e-05,  2.4301e-05],\n",
      "          [ 1.0867e-05,  2.4761e-05,  2.7322e-05,  2.7048e-05]]]])\n",
      "tensor([ 1.9072e-05, -7.2958e-05,  6.6082e-05, -1.8701e-05, -7.9366e-06,\n",
      "         1.7222e-05, -9.3647e-05, -1.9530e-05, -1.3148e-04, -8.7515e-05,\n",
      "         4.2594e-05, -1.1209e-04,  4.9228e-05,  9.4210e-05, -9.2925e-05,\n",
      "        -6.4934e-05])\n",
      "tensor([[[[-0.0002,  0.0013],\n",
      "          [ 0.0013,  0.0008]],\n",
      "\n",
      "         [[ 0.0021, -0.0048],\n",
      "          [-0.0046, -0.0032]],\n",
      "\n",
      "         [[ 0.0113, -0.0034],\n",
      "          [-0.0058, -0.0120]],\n",
      "\n",
      "         [[ 0.0027, -0.0035],\n",
      "          [-0.0021, -0.0039]],\n",
      "\n",
      "         [[ 0.0130, -0.0177],\n",
      "          [-0.0147, -0.0182]],\n",
      "\n",
      "         [[-0.0068,  0.0129],\n",
      "          [ 0.0208,  0.0051]],\n",
      "\n",
      "         [[ 0.0052, -0.0055],\n",
      "          [-0.0021, -0.0088]],\n",
      "\n",
      "         [[-0.0059,  0.0114],\n",
      "          [ 0.0064,  0.0131]],\n",
      "\n",
      "         [[ 0.0043, -0.0024],\n",
      "          [ 0.0015, -0.0100]],\n",
      "\n",
      "         [[-0.0091,  0.0180],\n",
      "          [ 0.0179,  0.0138]],\n",
      "\n",
      "         [[ 0.0065, -0.0085],\n",
      "          [-0.0033, -0.0090]],\n",
      "\n",
      "         [[ 0.0117, -0.0159],\n",
      "          [-0.0097, -0.0222]],\n",
      "\n",
      "         [[ 0.0072, -0.0102],\n",
      "          [-0.0045, -0.0104]],\n",
      "\n",
      "         [[ 0.0290, -0.0349],\n",
      "          [-0.0241, -0.0442]],\n",
      "\n",
      "         [[-0.0005, -0.0009],\n",
      "          [-0.0039,  0.0015]],\n",
      "\n",
      "         [[ 0.0156, -0.0194],\n",
      "          [-0.0137, -0.0256]]]])\n",
      "tensor([0.0003])\n",
      "tensor([[ 0.0062, -0.0253, -0.0264, -0.0234, -0.0072, -0.0449, -0.0383, -0.0358,\n",
      "          0.0030, -0.0333, -0.0332, -0.0325,  0.0032, -0.0335, -0.0332, -0.0331]])\n",
      "tensor([0.0010])\n"
     ]
    }
   ],
   "source": [
    "for p in mur_cnn_v1.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sonido",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
